{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommendation_Engine.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OrHZUN_enog"
      },
      "source": [
        "# CS4337 - MOVIE RECOMMENDATION PROJECT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWGy_Xe3zka5"
      },
      "source": [
        "18266401 AYOUB JDAIR\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP_BHtXnevig"
      },
      "source": [
        "# Section 1: Gathering user data ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-UiybCebKNJ"
      },
      "source": [
        "All my files have been uploaded to google drive. This cell mounts the drive in order for the code to work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKg-dtzVa9R6",
        "outputId": "a00d18e5-0e04-4a15-b1b7-399d331d2830"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMI0CqYA-kiB"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUgaa9HbIeGA",
        "outputId": "a96914ee-d6f6-4b37-e968-e9d49e48546d"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 70 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 33.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=7fba639cd84ca641fb6ebd21709c350ebde5c728c05124fe9f35a71cfa8785b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyV2BDvAHi6C"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "from time import time\n",
        "\n",
        "import sys\n",
        "import itertools\n",
        "from math import sqrt\n",
        "from operator import add\n",
        "from os.path import join, isfile, dirname\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.mllib.recommendation import ALS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWJBzjSQ-pQF"
      },
      "source": [
        "Collecting user input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-N0OwjzIjWy"
      },
      "source": [
        "topMovies = \"\"\"1,Toy Story (1995)\n",
        "780,Independence Day (a.k.a. ID4) (1996)\n",
        "590,Dances with Wolves (1990)\n",
        "1210,Star Wars: Episode VI - Return of the Jedi (1983)\n",
        "648,Mission: Impossible (1996)\n",
        "344,Ace Ventura: Pet Detective (1994)\n",
        "165,Die Hard: With a Vengeance (1995)\n",
        "153,Batman Forever (1995)\n",
        "597,Pretty Woman (1990)\n",
        "1580,Men in Black (1997)\n",
        "231,Dumb & Dumber (1994)\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSL_MI3NIl_4"
      },
      "source": [
        "parentDir = os.path.abspath('/content/drive/MyDrive/College/CS4337/movielens/medium/ayoub')\n",
        "ratingsFile = join(parentDir, \"personalRatings.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7weK3dHaIoLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b9e8e7-572a-4f35-a0ec-70e0cc29c28b"
      },
      "source": [
        "if isfile(ratingsFile):\n",
        "    r = input(\"Looks like you've already rated the movies. Overwrite ratings (y/N)? \")\n",
        "    if r and r[0].lower() == \"y\":\n",
        "        os.remove(ratingsFile)\n",
        "    else:\n",
        "        sys.exit()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looks like you've already rated the movies. Overwrite ratings (y/N)? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIZNtdMMIqea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6f265c-e49a-4bf6-b13b-563bab782ef3"
      },
      "source": [
        "prompt = \"Please rate the following movie (1-5 (best), or 0 if not seen): \"\n",
        "print(prompt)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please rate the following movie (1-5 (best), or 0 if not seen): \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kko8_2z5IsFY"
      },
      "source": [
        "now = int(time())\n",
        "n = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9yG7U5o-3az"
      },
      "source": [
        "Generating Personal Ratings file..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcZYcYjsItpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c42cd113-a1a2-4616-dcd2-d678440a3b86"
      },
      "source": [
        "f = open(ratingsFile, 'w')\n",
        "for line in topMovies.split(\"\\n\"):\n",
        "    ls = line.strip().split(\",\")\n",
        "    valid = False\n",
        "    while not valid:\n",
        "        rStr = input(ls[1] + \": \")\n",
        "        r = int(rStr) if rStr.isdigit() else -1\n",
        "        if r < 0 or r > 5:\n",
        "            print(prompt)\n",
        "        else:\n",
        "            valid = True\n",
        "            if r > 0:\n",
        "                f.write(\"0::%s::%d::%d\\n\" % (ls[0], r, now))\n",
        "                n += 1\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Toy Story (1995): 5\n",
            "Independence Day (a.k.a. ID4) (1996): 0\n",
            "Dances with Wolves (1990): 0\n",
            "Star Wars: Episode VI - Return of the Jedi (1983): 4\n",
            "Mission: Impossible (1996): 4\n",
            "Ace Ventura: Pet Detective (1994): 5\n",
            "Die Hard: With a Vengeance (1995): 4\n",
            "Batman Forever (1995): 4\n",
            "Pretty Woman (1990): 1\n",
            "Men in Black (1997): 3\n",
            "Dumb & Dumber (1994): 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhCnQeGyIwMB"
      },
      "source": [
        "if n == 0:\n",
        "    print(\"No rating provided!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMVr8LinslPv"
      },
      "source": [
        " #2: Doing maths stuff ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeMIq1Dt_JRO"
      },
      "source": [
        "Data loading/parsing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlgrOlbg_R7A"
      },
      "source": [
        "def parseRating(line):\n",
        "    \"\"\"\n",
        "    Parses a rating record in MovieLens format userId::movieId::rating::timestamp .\n",
        "    \"\"\"\n",
        "    fields = line.strip().split(\"::\")\n",
        "    return int(fields[3]) % 10, (int(fields[0]), int(fields[1]), float(fields[2]))\n",
        "\n",
        "\n",
        "def parseMovie(line):\n",
        "    \"\"\"\n",
        "    Parses a movie record in MovieLens format movieId::movieTitle .\n",
        "    \"\"\"\n",
        "    fields = line.strip().split(\"::\")\n",
        "    print(fields)\n",
        "    return int(fields[0]), fields[1]\n",
        "\n",
        "def loadRatings(ratingsFile):\n",
        "    \"\"\"\n",
        "    Load ratings from file.\n",
        "    \"\"\"\n",
        "    if not isfile(ratingsFile):\n",
        "        print(\"File %s does not exist.\" % ratingsFile)\n",
        "        sys.exit(1)\n",
        "    f = open(ratingsFile, 'r')\n",
        "    print(\"Opening ratings file...\")\n",
        "    print(\"PERSONAL RATINGS FILE located at:\\n\",ratingsFile)\n",
        "    ratings = filter(lambda r: r[2] > 0, [parseRating(line)[1] for line in f])\n",
        "    f.close()\n",
        "    if not ratings:\n",
        "        print(\"No ratings provided.\")\n",
        "        sys.exit(1)\n",
        "    else:\n",
        "        print(\"Ratings: \", ratings)\n",
        "        return ratings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIXcabGV_S_k"
      },
      "source": [
        "Calculating the Root Mean Squared Error Value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNz3Z5eu_gmI"
      },
      "source": [
        "def computeRmse(model, data, n):\n",
        "    \"\"\"\n",
        "    Compute RMSE (Root Mean Squared Error).\n",
        "    \"\"\"\n",
        "    predictions = model.predictAll(data.map(lambda x: (x[0], x[1])))\n",
        "    predictionsAndRatings = predictions.map(lambda x: ((x[0], x[1]), x[2])) \\\n",
        "      .join(data.map(lambda x: ((x[0], x[1]), x[2]))) \\\n",
        "      .values()\n",
        "    output = sqrt(predictionsAndRatings.map(lambda x: (x[0] - x[1]) ** 2).reduce(add) / float(n))\n",
        "    print(\"Computing RMSE...\")\n",
        "    print(\"Result! \", output)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwC_X3uQ_t4n"
      },
      "source": [
        "#Section 2: Gathering some more data ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tby9uXjr_5-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc7fdcd-e39a-4fe5-8fe0-6333f4014e45"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"--------IGNORE THIS (used to help me understand the data and code a little better)--------\\n\")\n",
        "    # set up environment\n",
        "    spark = SparkSession.builder \\\n",
        "   .master(\"local\") \\\n",
        "   .appName(\"Movie Recommendation Engine\") \\\n",
        "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
        "   .getOrCreate()\n",
        "   \n",
        "    sc = spark.sparkContext\n",
        "\n",
        "    # load personal ratings\n",
        "    print(\"Loading personal ratings file... \\n\")\n",
        "    myRatings = loadRatings(os.path.abspath('/content/drive/MyDrive/College/CS4337/movielens/medium/ayoub/personalRatings.txt'))\n",
        "    print(\"MyRatings: \", myRatings)\n",
        "    print(\"Converting myRatings file to RDD... \\n\")\n",
        "    myRatingsRDD = sc.parallelize(myRatings, 1)\n",
        "    print(\"Converted RDD: \", myRatingsRDD)\n",
        "    print(\"\\n-------------------------------------------------------------------------------------------\")\n",
        "\n",
        "    # load ratings and movie titles\n",
        "    movieLensHomeDir = os.path.abspath('/content/drive/MyDrive/College/CS4337/movielens/medium')\n",
        "\n",
        "    # ratings is an RDD of (last digit of timestamp, (userId, movieId, rating))\n",
        "    ratings = sc.textFile(join(movieLensHomeDir, \"ratings.dat\")).map(parseRating)\n",
        "\n",
        "    # movies is an RDD of (movieId, movieTitle)\n",
        "    movies = dict(sc.textFile(join(movieLensHomeDir, \"movies.dat\")).map(parseMovie).collect())\n",
        "\n",
        "\n",
        "    # your code here\n",
        "    # please scroll down ...\n",
        "\n",
        "\n",
        "    # # clean up\n",
        "    # sc.stop()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------IGNORE THIS (used to help me understand the data and code a little better)--------\n",
            "\n",
            "Loading personal ratings file... \n",
            "\n",
            "Opening ratings file...\n",
            "PERSONAL RATINGS FILE located at:\n",
            " /content/drive/MyDrive/College/CS4337/movielens/medium/ayoub/personalRatings.txt\n",
            "Ratings:  <filter object at 0x7f3586093a10>\n",
            "MyRatings:  <filter object at 0x7f3586093a10>\n",
            "Converting myRatings file to RDD... \n",
            "\n",
            "Converted RDD:  ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274\n",
            "\n",
            "-------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el9a_fV1GVh7"
      },
      "source": [
        "#Section 3: My code here ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSiAEOokGqwE"
      },
      "source": [
        "#-1 Create Training data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Ptf34Oy5ip"
      },
      "source": [
        "#-2 Create Testing data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmuA1OSTH_4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5736eafc-936a-4a15-8e8f-f952d93f46ea"
      },
      "source": [
        "# Here I am splitting the dataset into a training set and a testing set, 60% and 40% respectively\n",
        "# I will then evaluate the model on the testing set and\n",
        "# look at the RMSE value to evaluate performance.\n",
        "\n",
        "training_delta = ratings.filter(lambda x: x[0] < 6).values()\n",
        "# converting piplinedRDD back to RDD\n",
        "training = spark.sparkContext.parallelize(training_delta.collect())\n",
        "trainingCount = training.count()\n",
        "\n",
        "\n",
        "testing_delta = ratings.filter(lambda x: x[0] >= 6).values()\n",
        "# converting piplinedRDD back to RDD\n",
        "testing = spark.sparkContext.parallelize(testing_delta.collect())\n",
        "testingCount = testing.count()\n",
        "\n",
        "print(\"--------IGNORE THIS TOO--------\\n\")\n",
        "\n",
        "def percentage(percent, n):\n",
        "  return int((percent * n) / 100.0)\n",
        "\n",
        "entries = 1000209\n",
        "Ctraining = percentage(60, entries)\n",
        "Ctesting = percentage(40, entries)\n",
        "print(\"Training: \", trainingCount)\n",
        "print(\"Testing:\", testingCount)\n",
        "print(Ctraining, Ctesting)\n",
        "\n",
        "print(\"\\n---------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------IGNORE THIS TOO--------\n",
            "\n",
            "Training:  602241\n",
            "Testing: 397968\n",
            "600125 400083\n",
            "\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKAucGWNGv6a"
      },
      "source": [
        "#-3 Train the model\n",
        "-Using the ALS algorithm\n",
        "\n",
        "-Fit traing data to model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBtnTXP9PBbO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "outputId": "5683639e-9f30-4d09-823e-ec1faff3088e"
      },
      "source": [
        "%%html\n",
        "<iframe pointer-events:none; scrolling=\"no\" src=\"https://drive.google.com/file/d/1bTh1JLtC2u24PwfBaew8kw6XJUkKTa5K/preview\" width=\"1000\" height=\"450\" allow=\"autoplay\"></iframe>\n",
        "\n",
        "\n",
        "<!-- Image below from : \"Prototyping a Recommender System Step by Step Part 2: Alternating  -->\n",
        "<!--                    Least Square (ALS) Matrix Factorization in Collaborative Filtering\" -->\n",
        "<!--                    - Kevin Liao -->\n",
        "<!-- Link: https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1 -->"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<iframe pointer-events:none; scrolling=\"no\" src=\"https://drive.google.com/file/d/1bTh1JLtC2u24PwfBaew8kw6XJUkKTa5K/preview\" width=\"1000\" height=\"450\" allow=\"autoplay\"></iframe>\n",
              "\n",
              "\n",
              "<!-- Image below from : \"Prototyping a Recommender System Step by Step Part 2: Alternating  -->\n",
              "<!--                    Least Square (ALS) Matrix Factorization in Collaborative Filtering\" -->\n",
              "<!--                    - Kevin Liao -->\n",
              "<!-- Link: https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1 -->"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_bspHeBLtsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e9a298-ffe1-4ea8-e1e5-eb5dc92488da"
      },
      "source": [
        "# Here I am using the ALS library imported from MLLIB in the provided code\n",
        "# Since we are using MLLIB and not ML, i am calling the .train() method from ALS\n",
        "#  This method takes in the data set in the form of an RDD, this is why I converted above\n",
        "\n",
        "# The parameters used to train the model are as follows:\n",
        "# 1 - \"training\"      : The trainng set created above\n",
        "# 2 - \"rank\"          : Rank is used for the matrix factorisation part of ALS,\n",
        "#                       it is effectively the width of the matrix \"User Matrix\" and \"Item Matrix\" in the above image\n",
        "# 3 - \"iterations\"    : Amount of epochs, how many times we will preform the action in the image above.\n",
        "# 4 - \"lambda_\"       : Prevents overfitting in the model\n",
        "# 5 - \"nonnenegative\" : This is true becasue we do not want the model to return any negative predictions\n",
        "\n",
        "# I will then call the provided \"computeRmse()\" and pass in:\n",
        "# 1 - My model\n",
        "# 2 - My testing data set\n",
        "# 3 - And count() of my testing data set, declared above\n",
        "\n",
        "model = ALS.train(training, rank=8, iterations=20, lambda_=0.07, nonnegative=True)\n",
        "testingRMSE = computeRmse(model, testing, testingCount)\n",
        "format_RMSE = \"{:.2f}\".format(testingRMSE)\n",
        "print(\"Calculated RMSE on Model: \", format_RMSE)\n",
        "\n",
        "# I spent a considerable amount of time tweaking \"rank\" , \"iterations\", and \"lambda_\"\n",
        "# and found that 8, 20, and 0.07 have provided the best model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing RMSE...\n",
            "Result!  0.8686590127072287\n",
            "Calculated RMSE on Model:  0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vly4ZWefHPBw"
      },
      "source": [
        "-Predict using testing data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVO5dWvJRVD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b083c1-096e-45af-bbd6-f323c2f0e53e"
      },
      "source": [
        "# Here I will be making my predictions using the predictAll() method\n",
        "# I will first make a list of movies I have rated\n",
        "# I will use this list to make sure my list of possible recomendations does not include\n",
        "# i have already rated\n",
        "# Finally, i will let you choose how many recomendations you would like\n",
        "myRatedMoviesSet = set([x[1] for x in myRatings])\n",
        "possibleRecommendations = sc.parallelize([m for m in movies if m not in myRatedMoviesSet])\n",
        "predictions = model.predictAll(possibleRecommendations.map(lambda x: (1, x))).collect()\n",
        "n = int(input(\"How many recommendations would you like?: \"))\n",
        "recommendations = sorted(predictions, key=lambda x: x[2], reverse=True)[:n]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many recommendations would you like?: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSHFo6FHHW_t"
      },
      "source": [
        "#-4 Return recommendation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIfu7j0feom9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64dc94dc-a543-4603-f641-bab74299a71e"
      },
      "source": [
        "print(\"Here are the top %d Movies recommended for you:\" % n)\n",
        "for i in range(len(recommendations)):\n",
        "  j = n-i\n",
        "  print(\"Number \", j, \": \", movies[recommendations[i][1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the top 10 Movies recommended for you:\n",
            "Number  10 :  Gambler, The (A J�t�kos) (1997)\n",
            "Number  9 :  Tic Code, The (1998)\n",
            "Number  8 :  American Dream (1990)\n",
            "Number  7 :  Visitors, The (Les Visiteurs) (1993)\n",
            "Number  6 :  Anne Frank Remembered (1995)\n",
            "Number  5 :  Train of Life (Train De Vie) (1998)\n",
            "Number  4 :  Bewegte Mann, Der (1994)\n",
            "Number  3 :  Before the Rain (Pred dozhdot) (1994)\n",
            "Number  2 :  Smashing Time (1967)\n",
            "Number  1 :  Aim�e & Jaguar (1999)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql35H_uMHfzA"
      },
      "source": [
        "#-5 Report the accuracy of the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUQXLYgupo9i"
      },
      "source": [
        "*I spent a considerable amount of time tweaking the \"rank\" , \"iterations\", and \"lambda_\" paramters in ALS.train() and found that 8, 20, and 0.07 have provided the best model. This means the models predictions will off by 0.86 which I see to be an acceptable result and accuracy rate. If provided with more time this could possilbly be improved.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA7nkWyZADBx"
      },
      "source": [
        "#Section 4: Finishing touches ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk5OZABLAOQT"
      },
      "source": [
        "Closing up shop..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSt5EW7qAM2O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45575a7c-1039-4d42-83a5-c153481fac10"
      },
      "source": [
        "    sc.stop()\n",
        "    print(\"----------------------------------------NOTES FOR XXXX-----------------------------------------\\n\")\n",
        "    print(\"\\n\")\n",
        "    print(\"--------------------------------------THANK YOU FOR READING-------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------NOTES FOR SAHIR-----------------------------------------\n",
            "\n",
            "Because I have laid out this submission in such a way to make it easier for you to follow along,\n",
            "and see my process by deviding up the cells and putting headers and text between them, \n",
            "running iindividual cells can sometimes be troublsome. \n",
            "I have extensively tested this code before submission and can guarantee it runs on my machine \n",
            "Please run from main and 'After' or all togther if that dosnt work\n",
            "Please run on collab.research.google.com if possible as you are aware that I had alot \n",
            "of trouble setting up pyspark on my mac, I ended up using google collab in an effort to catch up \n",
            "because of the significant time I had lost. My files are also hosted on google Drive.\n",
            "I suspect that my submittion will also run on jupyer notebook as they are both .ipynb but \n",
            "this is just an FYI that I resorted to using collab in the end.\n",
            "\n",
            "--------------------------------------THANK YOU FOR READING-------------------------------------\n"
          ]
        }
      ]
    }
  ]
}